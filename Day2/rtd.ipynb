{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RTD - Replaced Token Detection\n",
    "\n",
    "RTD is an alternative to the traditional Masked Language Model (MLM) objective. Instead of masking tokens and predicting them (as in BERT), RTD randomly replaces tokens in a sentence and trains the model to identify whether each token is the original or a replaced one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46a24635eef442ba17cd0158156c808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Basudev\\genaiprereq\\Day1\\gnipre\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--google--electra-small-discriminator. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba70357fc8a7495db9ca4b60147974ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b1739ecdcb4d569b13b1e69b9d1c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049e0c337043492697498b817a3e3767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e774dcf3be8f4dc4918abdc4c10f0826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/54.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: [CLS]      | Status: Replaced\n",
      "Token: the        | Status: Replaced\n",
      "Token: quick      | Status: Replaced\n",
      "Token: brown      | Status: Replaced\n",
      "Token: cat        | Status: Replaced\n",
      "Token: jumps      | Status: Replaced\n",
      "Token: over       | Status: Replaced\n",
      "Token: sleepy     | Status: Replaced\n",
      "Token: lazy       | Status: Replaced\n",
      "Token: dog        | Status: Replaced\n",
      "Token: .          | Status: Replaced\n",
      "Token: [SEP]      | Status: Replaced\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf48392033054a41996cb9a901ed1ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/54.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForPreTraining\n",
    "import torch\n",
    "\n",
    "# Load pre-trained ELECTRA model and tokenizer\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n",
    "model = ElectraForPreTraining.from_pretrained(\"google/electra-small-discriminator\")\n",
    "\n",
    "# Sample sentence\n",
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenize the input sentence\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "# Introduce token replacements to simulate the RTD task\n",
    "# For demonstration, let's replace \"fox\" with \"cat\" and \"lazy\" with \"sleepy\"\n",
    "inputs[\"input_ids\"][0][4] = tokenizer.convert_tokens_to_ids(\"cat\")  # Replacing \"fox\" with \"cat\"\n",
    "inputs[\"input_ids\"][0][7] = tokenizer.convert_tokens_to_ids(\"sleepy\")  # Replacing \"lazy\" with \"sleepy\"\n",
    "\n",
    "# Run the model on the modified sentence\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# The model's output contains logits where each token has a \"real\" or \"fake\" prediction\n",
    "predictions = torch.round(torch.sigmoid(outputs.logits))\n",
    "\n",
    "# Decode the tokens and print out the RTD results\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "for token, prediction in zip(tokens, predictions[0]):\n",
    "    status = \"Real\" if prediction.item() == 1 else \"Replaced\"\n",
    "    print(f\"Token: {token:<10} | Status: {status}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnipre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
